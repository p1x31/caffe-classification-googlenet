{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget --header=\"Host: downloader-default2h.disk.yandex.net\" --header=\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,ru;q=0.8\" --header=\"Referer: https://yadi.sk/d/2KZaTHeWIXq79w\" \"https://downloader-default2h.disk.yandex.net/rzip/9662d8963f53a3f162902b06d872a768de0761f1d57bcca29ed85ae1a19f90f6/5f8458de/QWpFSFdsWW5EMjY3Y3U5QnFIVDV4MkZJTytkR1YxOUp5aWtZbUNMR2EwOWFxeW1reGhBdlcxQ0V5d3lmVm1tUXEvSjZicG1SeU9Kb25UM1ZvWG5EYWc9PQ==?uid=0&filename=ForVadim.zip&disposition=attachment&hash=AjEHWlYnD267cu9BqHT5x2FIO%2BdGV19JyikYmCLGa09aqymkxhAvW1CEywyfVmmQq/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&owner_uid=204301488&tknv=v2&rtoken=lGxbL9ARbqbb&force_default=no&ycrid=na-32f56c4a6729a6576d0b2a22143f1e21-downloader17h\" -c -O 'ForVadim.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import Tensor\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, pool_proj,\n",
    "                 conv_block=None):\n",
    "        super(Inception, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "            \n",
    "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = conv_block(in_channels, ch3x3red, kernel_size=1)\n",
    "\n",
    "\n",
    "    def _forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "\n",
    "\n",
    "        outputs = [branch1, branch2]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x, inplace=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [BasicConv2d, Inception]\n",
    "conv_block = blocks[0]\n",
    "inception_block = blocks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./weights/model_297.pt\"\n",
    "model = torch.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): LocalResponseNorm(5, alpha=9.9999997e-05, beta=0.75, k=1.0)\n",
       "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (2): Inception(\n",
       "      (branch1): BasicConv2d(\n",
       "        (conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (branch2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): AdaptiveAvgPool2d(output_size=(22, 22))\n",
       "    (4): Dropout(p=0.20000001, inplace=False)\n",
       "    (5): Sequential(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (fc1): Linear(in_features=11616, out_features=3, bias=True)\n",
       "      (output): LogSoftmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "preds = []\n",
    "\n",
    "def predict_frame(currentFrame):\n",
    "    currentFrame = np.array(currentFrame)\n",
    "    currentFrame = cv2.resize(np.float32(currentFrame),(size,size))\n",
    "    currentFrame = currentFrame.reshape(1,3,224,224).astype('float')\n",
    "    currentFrame = currentFrame/255\n",
    "    currentFrame = torch.from_numpy(currentFrame)\n",
    "    currentFrame = currentFrame.to(device, dtype=torch.float)\n",
    "    prob = loadedModel(currentFrame)\n",
    "    #max_prob = max(prob[0])\n",
    "    max_prob = prob.max(dim=1, keepdim=True)\n",
    "    max_prob = 1 + max_prob[0]\n",
    "    max_prob = max_prob.detach().cpu().numpy()\n",
    "    pred = prob.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "    pred = pred.cpu().numpy()\n",
    "    \n",
    "    if pred == [[2]]:\n",
    "        return \"car\", max_prob\n",
    "    elif pred == [[1]]:\n",
    "        return \"human\", max_prob\n",
    "    else:\n",
    "        return \"none\", max_prob\n",
    "    #if(max_prob>.90):\n",
    "    #   return pred , max_prob\n",
    "    \n",
    "\n",
    "# main function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    loadedModel = model\n",
    "    filename = \"scene.avi\"\n",
    "    PATH = \"./ForVadim/{}\".format(filename)\n",
    "    camera = cv2.VideoCapture(PATH)\n",
    "\n",
    "    show_pred = False\n",
    "    # loop until interrupted\n",
    "    while (True):\n",
    "        \n",
    "        (grabbed,frame) = camera.read()\n",
    "        frame = imutils.resize(frame,width = 700)\n",
    "        #flip around y-axis\n",
    "        frame = cv2.flip(frame,1)\n",
    "        \n",
    "        clone = frame.copy()\n",
    "        \n",
    "        (height,width) = frame.shape[:2]\n",
    "        #potential speedup if converted to grayscale, net should intake grayscale as well\n",
    "        #grayClone = cv2.cvtColor(clone,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #frame = np.float32(frame)\n",
    "        #frame = torch.from_numpy(frame)\n",
    "        #frame = frame.to(device)\n",
    "        label, prob = predict_frame(frame)\n",
    "\n",
    "        keypress_toshow = cv2.waitKey(1)\n",
    "        \n",
    "        if(keypress_toshow == ord(\"e\")):\n",
    "            show_pred = not show_pred\n",
    "        \n",
    "        #hershey font (image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "        if(show_pred):\n",
    "            cv2.putText(clone , str(label)+' '+str(prob*100)+'%' , (30,30) , cv2.FONT_HERSHEY_DUPLEX , 1 , (0,255,0) , 1)\n",
    "\n",
    "        #cv2.imshow(\"GrayClone\",grayClone)\n",
    "        \n",
    "        #cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        cv2.imshow(\"Video Feed\", clone)\n",
    "\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if(keypress == ord(\"q\")):\n",
    "            break\n",
    "\n",
    "camera.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
