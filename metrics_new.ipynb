{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       300\n",
      "           1       0.96      0.99      0.98       300\n",
      "           2       0.99      0.98      0.98       300\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       900\n",
      "   macro avg       0.98      0.98      0.98       900\n",
      "weighted avg       0.98      0.98      0.98       900\n",
      " samples avg       0.98      0.98      0.98       900\n",
      "\n",
      "FPS: 43.75 fps\n",
      "mAP: 0.9896296296296297\n",
      "Total number of parameters: 659136\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_adam))\n",
    "print(fps_adam)\n",
    "print('mAP: ' + mAP_adam)\n",
    "print (\"Total number of parameters: \" + params_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "import glob\n",
    "from numpy import prod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_root = '/home/vadim/caffe/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_device(0)  # if we have multiple GPUs, pick the first one\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "model_def = 'deploy_1module_head.prototxt'\n",
    "model_weights = '1module_iter_1116.caffemodel'\n",
    "#model_def = 'deploy_1module_head_reduce.prototxt'\n",
    "#model_weights = '1module_iter_1584.caffemodel'\n",
    "\n",
    "\n",
    "net_adam = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: <zip object at 0x7fb9ac38d1e0>\n"
     ]
    }
   ],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print ('mean-subtracted values:', zip('BGR', mu))\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net_adam.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the size of the input (we can skip this if we're happy\n",
    "#  with the default; we can also change it later, e.g., for different batch sizes)\n",
    "#net.blobs['data'].reshape(50,        # batch size\n",
    "#                          3,         # 3-channel (BGR) images\n",
    "#                          224, 224)  # image size is 224\n",
    "net_adam.blobs['data'].reshape(64,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t(64, 3, 224, 224)\n",
      "conv1/7x7_s2\t(1, 64, 112, 112)\n",
      "pool1/3x3_s2\t(1, 64, 56, 56)\n",
      "pool1/norm1\t(1, 64, 56, 56)\n",
      "conv2/3x3_reduce\t(1, 64, 56, 56)\n",
      "conv2/3x3\t(1, 192, 56, 56)\n",
      "conv2/norm2\t(1, 192, 56, 56)\n",
      "pool2/3x3_s2\t(1, 192, 28, 28)\n",
      "pool2/3x3_s2_pool2/3x3_s2_0_split_0\t(1, 192, 28, 28)\n",
      "pool2/3x3_s2_pool2/3x3_s2_0_split_1\t(1, 192, 28, 28)\n",
      "pool2/3x3_s2_pool2/3x3_s2_0_split_2\t(1, 192, 28, 28)\n",
      "pool2/3x3_s2_pool2/3x3_s2_0_split_3\t(1, 192, 28, 28)\n",
      "inception_3a/1x1\t(1, 64, 28, 28)\n",
      "inception_3a/3x3_reduce\t(1, 96, 28, 28)\n",
      "inception_3a/3x3\t(1, 128, 28, 28)\n",
      "inception_3a/5x5_reduce\t(1, 16, 28, 28)\n",
      "inception_3a/5x5\t(1, 32, 28, 28)\n",
      "inception_3a/pool\t(1, 192, 28, 28)\n",
      "inception_3a/pool_proj\t(1, 32, 28, 28)\n",
      "inception_3a/output\t(1, 256, 28, 28)\n",
      "pool5/7x7_s1\t(1, 256, 22, 22)\n",
      "loss3/classifier_new\t(1, 3)\n",
      "softmax\t(1, 3)\n"
     ]
    }
   ],
   "source": [
    "# for each layer, show the output shape\n",
    "for layer_name, blob in net_adam.blobs.items():\n",
    "    print (layer_name + '\\t' + str(blob.data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'human', 'noise']\n"
     ]
    }
   ],
   "source": [
    "categories=[x.strip() for x in open('labels_adam.txt').readlines()]\n",
    "print (categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 43.75 fps\n",
      "CPU times: user 22.1 s, sys: 67.3 ms, total: 22.2 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_adam = []\n",
    "from timeit import default_timer as timer\n",
    "time_start = timer()\n",
    "#this is very ineffective O(n^2)+complexity of network\n",
    "for i, x in enumerate(categories):\n",
    "    for j, y in enumerate(sorted(glob.glob('Data/test/{}/*'.format(x)))):\n",
    "        net_adam.blobs['data'].data[...] = transformer.preprocess('data',caffe.io.load_image(y))\n",
    "        net_adam.reshape()\n",
    "        pred = net_adam.forward()\n",
    "        preds_adam.append(np.argmax(pred['softmax']))\n",
    "        #print(y, categories[np.argmax(pred['softmax'])])\n",
    "\n",
    "time_end = timer()\n",
    "fps_adam=('FPS: %.2f fps' % (1000/(time_end-time_start)))\n",
    "print('FPS: %.2f fps' % (1000/(time_end-time_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " ...\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# convert the data and labels to NumPy arrays\n",
    "preds_adam = np.array(preds_adam)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "preds_adam = lb.fit_transform(preds_adam)\n",
    "#preds = to_categorical(preds)\n",
    "print(preds_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 659136\n"
     ]
    }
   ],
   "source": [
    "params_adam = str(sum([prod(v[0].data.shape) for k, v in net_adam.params.items()]))\n",
    "print (\"Total number of parameters: \" + str(sum([prod(v[0].data.shape) for k, v in net_adam.params.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = '/home/vadim/testovoe/dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(CURRENT_DIR+\"Data/text.txt\", sep=\"\\s+\", header=None, names=[\"name\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_width(im, new_shape, is_rgb=True):\n",
    "    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n",
    "    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n",
    "    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n",
    "    if is_rgb:\n",
    "        pad_width = ((t,b), (l,r), (0, 0))\n",
    "    else:\n",
    "        pad_width = ((t,b), (l,r))\n",
    "    return pad_width\n",
    "\n",
    "def preprocess_image(image_path, desired_size=224):\n",
    "    im = Image.open(image_path)\n",
    "    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:00<00:00, 1076.77it/s]\n"
     ]
    }
   ],
   "source": [
    "N = test_df.shape[0]\n",
    "x_test = np.empty((N, 224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(tqdm(test_df['name'])):\n",
    "    x_test[i, :, :, :] = preprocess_image(\n",
    "         f'/home/vadim/testovoe/dev/{image_id}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.get_dummies(test_df['category']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car' 'human' 'noise']\n"
     ]
    }
   ],
   "source": [
    "labels_file = 'labels_adam.txt'\n",
    "\n",
    "labels = np.loadtxt(labels_file, str, delimiter='\\t')\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       300\n",
      "           1       0.96      0.99      0.98       300\n",
      "           2       0.99      0.98      0.98       300\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       900\n",
      "   macro avg       0.98      0.98      0.98       900\n",
      "weighted avg       0.98      0.98      0.98       900\n",
      " samples avg       0.98      0.98      0.98       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9896296296296297\n"
     ]
    }
   ],
   "source": [
    "mAP_adam = str(average_precision_score(y_test, preds_adam, average=\"samples\"))\n",
    "print(average_precision_score(y_test, preds_adam, average=\"samples\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
